from scrapy import signals, Item, Request
import logging
import os
from IPython import embed
from scrapy.utils.request import request_fingerprint
from scrapyprj.replay.ReplayStorage import ReplayStorage
from scrapyprj.replay.ReplayRequest import ReplayRequest
import traceback
from scrapy.exceptions import CloseSpider

# This middleware takes care of saving / reloading request from the file systems.
class ReplaySpiderMiddleware(object):
	SPIDER_ATTRIBUTE = '__replay_middleware__'
	STORAGE_FOLDER = 'replayfolder'
	def __init__(self, settings):
		if 'MODE' in settings:
			self.replay = True if settings['MODE'] == 'replay' else False
		else:
			self.replay = False

		self.logger = logging.getLogger('ReplaySpiderMiddleware')
		self.storage = None
		self.folder_deleted = {}
		self.item_buffer = []
		self.filenames_by_fingerprint = {}
		self.remaining_filenames = {}

	@classmethod
	def from_crawler(cls, crawler):
		o = cls(crawler.settings)
		crawler.signals.connect(o.spider_opened, signal=signals.spider_opened)
		return o

	def spider_opened(self, spider):
		self.storage = ReplayStorage(spider, self.STORAGE_FOLDER)
		if not self.replay and spider.name not in self.folder_deleted:
			self.folder_deleted[spider.name]  = True
			try:
				self.storage.backup_dir()
			except Exception as e:
				self.logger.error("Cannot backup replay folder. Exiting.\n %s" % (e))
				raise CloseSpider('Cannot backup replay folder.')
			self.storage.delete_dir()
			self.storage.make_dir()

		if self.replay:
			setattr(spider, self.SPIDER_ATTRIBUTE, self)	# We need to do some work in spider IDLE callback. So we give the spider a reference tot his middleware 

	def process_spider_input(self, response, spider):
		if not self.replay:		# When crawling, saves responses.
			self.save(response, spider)

	def process_spider_output(self, response, result, spider):
		for x in result:
			if self.replay:
				if isinstance(x, Item): 
					yield x
				elif isinstance(x, Request): 	# When a request comes in, find it on the filesystem and replays the repsonse
					requests_generator = self.yield_responses_from_spider_request(x, spider) 	# This returns a ReplayRequest which already contain the response.
					if requests_generator is not None:
						for request in requests_generator:
							yield request
				else:
					yield x
			else:
				yield x

	def process_start_requests(self, start_requests, spider):
		if self.replay:
			for responseinfo in self.storage.saved_response_info():
				if responseinfo.fingerprint not in self.filenames_by_fingerprint:	# Initialize the request dict
					self.filenames_by_fingerprint[responseinfo.fingerprint] = []

				self.filenames_by_fingerprint[responseinfo.fingerprint].append(responseinfo.filename) # Make a dict of fingerprint / request filename
				self.remaining_filenames[responseinfo.filename] = True	# When a request will be replayed, this entry will beremoved. We will only yield each request once.

			for x in start_requests:
				requests_generator = self.yield_responses_from_spider_request(x, spider)	# This returns a ReplayRequest which already contain the response.
				if requests_generator is not None:
					for request in requests_generator:
						yield request
		else:
			for x in start_requests:
				yield x

	# Takes a request generated by the spider. Finds its equivalent on the filesystem and return the saved response from previous crawl.
	def yield_responses_from_spider_request(self, request, spider):
		fingerprint = request_fingerprint(request)
		if fingerprint in self.filenames_by_fingerprint:
			for filename in self.filenames_by_fingerprint[fingerprint]:
				if filename in self.remaining_filenames:
					del self.remaining_filenames[filename]
					yield self.make_request_from_response(self.storage.load(filename, spider))

	# Pop a single request from the filesystem, starting from the oldes. 
	# This will be used when IDLE to avoid stopping the replay if the request that has been 
	# yielded by the spider does not match the filesystem.
	def pop_remaining_replay_request(self, spider):
		while len(self.remaining_filenames) > 0:
			filename = self.remaining_filenames.keys()[0]
			response = self.storage.load(filename, spider)
			
			if response.request is not None:
				request = self.make_request_from_response(response)
			else:
				request = None
				self.logger.info('Discarding saved response with no request')
			
			del self.remaining_filenames[filename]
			
			if request is not None:
				return request

	def process_spider_exception(self, response, exception, spider):
		self.logger.error("%s \n %s" % (exception, traceback.format_exc()))

	# Make a request the the replay_downloader_middleware will recognize
	def make_request_from_response(self, response):
		request = response.request.copy()
		request.meta['shared'] = False
		request._meta['__replay__response__'] = response
		return request
	
	def save(self, response, spider):
		try:
			self.storage.save(response, spider)
		except Exception as e:
			self.logger.error("%s \n %s" % (e, traceback.format_exc()))
